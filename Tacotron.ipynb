{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tacotron.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "u9aAZaJvH4HI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Tacotron with TensorFlow</h1>\n",
        "Possible datasets (from Jira):\n",
        "\n",
        "<a href=\"http://www.openslr.org/12/\">open slr</a> - The data used\n",
        "\n",
        "<a href=\"https://medium.com/@klintcho/creating-an-open-speech-recognition-dataset-for-almost-any-language-c532fb2bc0cf\">audiobooks</a>\n",
        "\n",
        "<a href=\"https://datashare.is.ed.ac.uk/handle/10283/2651\">datashare</a>\n",
        "\n",
        "<a href=\"https://voice.mozilla.org/en/data \">Mozilla voice</a> - just realized this is 12gb\n",
        "\n",
        "<a href=\"https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html\">link</a> to actual Tacotron2 thing by Google\n",
        "\n",
        "<a href=\"https://github.com/r9y9/wavenet_vocoder\">link</a> to wavenet vocoder"
      ]
    },
    {
      "metadata": {
        "id": "rRPmkOvmET-f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install libsndfile1\n",
        "!pip install soundfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENV3H84TFtg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run above in case the soundfile import doesn't work"
      ]
    },
    {
      "metadata": {
        "id": "aeSY1QaYG_Hf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import statements\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import scipy.signal as signal\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8QR65rcH2Pa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I'm not sure how you want to download the data from the datasets\n",
        "if you drop it into your google drive root directory, we can use code similar to the stuff below and access it. Also, do you have any prefrence on what data set to use?"
      ]
    },
    {
      "metadata": {
        "id": "BqeTVonINuH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-FKhD4T8Nag",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data preprocessing, generating spectrograms from flac files (using the libslr data, 61-70968 files uplaoded into colab)."
      ]
    },
    {
      "metadata": {
        "id": "JavKGmk59aev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getSpec(file, dirp, save=True):\n",
        "  data, samplerate = sf.read(file)\n",
        "  s = melspectrogram(data,samplerate)\n",
        "  if save:\n",
        "    plt.pcolormesh(s)\n",
        "    plt.savefig(dirp+file.split('.')[0]+'.png')\n",
        "  return s\n",
        "  #plt.pcolormesh(time,freq,spec) #uncomment to see the spectrogram\n",
        "  #is spectrogram wavenet compatible?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsN-e8r_JjJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def makeSpecs():\n",
        "  #rm -r spectrograms/ #run to delete the folder\n",
        "  auio_ext = \"flac\"\n",
        "  audio_files = [s for s in os.listdir() if len(s.split('.'))>1 and s.split('.')[1] == auio_ext]\n",
        "  os.makedirs('spectrograms', exist_ok=True)\n",
        "  return [getSpec(file,'spectrograms/') for file in audio_files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JD76UZCdL76D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "618b77f0-e022-43cf-9466-db0e353179ed"
      },
      "cell_type": "code",
      "source": [
        "output_spec = makeSpecs()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X+MFOUdx/HP7u0dx8Eh3MlisBWp\nsWoapBLaFCoqBW2srVoNxl5Oa1JTbRVpYwNIjNrYFAE1rWiqIlYjmhKvreUPA8QYG1NPGsUQMWmo\nNrEWKRwIHN7P3dnpH/QZ5ubm9ufs7nO771fSUPd2Z5+dmd3vPN95nu8Tc13XFQAAqKp4tRsAAAAI\nyAAAWIGADACABQjIAABYgIAMAIAFCMgAAFiAgAwAgAUIyAAAWICADACABQjIAABYgIAMAIAFCMgA\nAFiAgAwAgAUIyAAAWICADACABQjIAABYgIAMAIAFCMgAAFiAgAwAgAUIyAAAWICADACABfIKyPv2\n7dPSpUu1ZcsWSdKBAwd0yy23qLOzU7fccot6enokSdu2bdP111+vZcuW6eWXXy5fqwEAqDE5A3J/\nf78efPBBLViwwHvsN7/5jW644QZt2bJFl19+uX7/+9+rv79fTzzxhJ577jm98MILev7553Xs2LGy\nNh4AgFqRMyA3NTVp06ZNSiaT3mP333+/vv3tb0uSpk2bpmPHjmnPnj2aM2eOWltb1dzcrHnz5mn3\n7t3lazkAADUkZ0BOJBJqbm4e8VhLS4saGhrkOI5eeuklfe9739Phw4fV1tbmPaetrc1LZQMAgOyK\nHtTlOI5Wrlypb3zjGyPS2YbruiU1DACAelJ0QL7nnns0a9Ys3XnnnZKkZDKpw4cPe38/dOjQiDQ3\nAAAYW1EBedu2bWpsbNRdd93lPTZ37ly9//776u3tVV9fn3bv3q358+dH1lAAAGpZzM2RW967d6/W\nrVun/fv3K5FIaMaMGTpy5IgmTJigyZMnS5LOOeccPfDAA9q+fbs2b96sWCymzs5OXX311RX5EAAA\njHc5AzIAACg/KnUBAGABAjIAABYgIAMAYAECMgAAFiAgAwBgAQIyAAAWICADAGABAjIAABYgIAMA\nYAECMgAAFiAgAwBgAQIyAAAWICADAGABAjIAABYgIAMAYAECMgAAFiAgAwBgAQIyAAAWICADAGAB\nAjIAABYgIAMAYAECMgAAFiAgAwBgAQIyAAAWICADAGABAjIAABYgIAMAYAECMgAAFiAgAwBgAQIy\nAAAWICADAGABAjIAABYgIAMAYAECMgAAFiAgAwBgAQIyAAAWICADAGABAjIAABbIKyDv27dPS5cu\n1ZYtWyRJBw4c0E033aSOjg6tWLFCw8PDkqRt27bp+uuv17Jly/Tyyy+Xr9UAANSYnAG5v79fDz74\noBYsWOA99thjj6mjo0MvvfSSZs2apa6uLvX39+uJJ57Qc889pxdeeEHPP/+8jh07VtbGAwBQK3IG\n5KamJm3atEnJZNJ7bNeuXVqyZIkkafHixeru7taePXs0Z84ctba2qrm5WfPmzdPu3bvL13IAAGpI\nIucTEgklEiOfNjAwoKamJklSe3u7enp6dPjwYbW1tXnPaWtrU09PT8TNBQCgNpU8qMt13YIeBwAA\noxUVkFtaWjQ4OChJOnjwoJLJpJLJpA4fPuw959ChQyPS3AAAYGxFBeSFCxdqx44dkqSdO3dq0aJF\nmjt3rt5//3319vaqr69Pu3fv1vz58yNtLAAAtSrm5sgt7927V+vWrdP+/fuVSCQ0Y8YMPfzww1q9\nerWGhoY0c+ZMrV27Vo2Njdq+fbs2b96sWCymzs5OXX311ZX6HAAAjGs5AzIAACg/KnUBAGABAjIA\nABYgIAMAYAECMgAAFiAgAwBgAQIyAAAWICADAGABAjIAABYgIAMAYAECMgAAFiAgAwBgAQIyAAAW\nICADAGABAjIAABYgIAMAYAECMgAAFiAg1zHXdavdBADA/xGQAQCwAAG5jsVisWo3AQDwfwRkAAAs\nQECuY9xDBgB7EJABALAAARkAAAsQkOsYg7oAwB4EZAAALEBABgDAAgRkAAAsQEAGAMACBGQAACxA\nQAYAwAKJajeg0lzXVSaTkSTF4yevR5j+AwCoNnrIAABYoO56yKZ3LNEzBgDYgx4yAAAWiLl1tuRP\n2MelpwwAqDZ6yAAAWICADACABYoa1NXX16dVq1bp+PHjSqVSuuOOOzR9+nQ98MADkqTzzjtPv/zl\nL6NsZ6TMwC6TqiZlDQCotqIC8p///GfNnj1bd999tw4ePKgf/vCHmj59utasWaMLL7xQd999t/76\n17/q0ksvjbq9AADUpKJS1tOmTdOxY8ckSb29vZo6dar279+vCy+8UJK0ePFidXd3R9fKCGUyGcXj\n8RH/AwCg2oqKRldddZU+/fRTXX755ers7NTKlSs1ZcoU7+/t7e3q6emJrJEAANS6olLWf/nLXzRz\n5kxt3rxZ//jHP3THHXeotbXV+7vNM6ni8TilMwEA1ikqIO/evVsXX3yxJOn888/X0NCQ0um09/eD\nBw8qmUxG00IAAOpAUSnrWbNmac+ePZKk/fv3a9KkSTrnnHP0zjvvSJJ27typRYsWRddKAABqXFGV\nuvr6+rRmzRodOXJE6XRaK1as0PTp03Xfffcpk8lo7ty5uueee8rR3pKlUikNDw9LkpqbmyVJDQ0N\n1WwSAAD1VzqTgAwAsFHdBWTHcbxBXEx5AgDYgogEAIAF6q6HLI2elsW0JwBAtdFDBgDAAgRkAAAs\nUFRhkPHMcRw5jiPp1OhqRlkDAKqNHjIAABaomx6yGciVTqeVSJz82PSMAQC2oIcMAIAF6m7ak+u6\nTHMCAFiHHjIAABYgIAMAYIG6C8ixWEyu646q1gUAQDXVXUAGAMBGdReQ6RkDAGxUdwEZAAAb1U1h\nED+mPQEAbEMPGQAACxCQAQCwQN0FZNLVAAAb1V1ABgDARgRkAAAsQEAGAMACBGQAACxAQAYAwAIE\nZAAALFB3AbmUWtasEoVaxHkN2KHuAjIAADaKuVwaAwBQdfSQAQCwQF2u9lQMfyKB8puoJZlMRpIU\nj3N9DlQT30AAACxAQAYAwAIE5DyRpkatisVinN+ABQjIAABYgGlPAABYgB4yAAAWICADdY7SmYAd\nip6HvG3bNj3zzDNKJBK66667dN5552nlypVyHEfTp0/Xhg0b1NTUFGVbAQCoWUXdQz569KhuvPFG\n/fGPf1R/f782btyodDqtSy65RFdeeaUeffRRnXHGGero6ChHmwFEyPwEMNIaqK6iUtbd3d1asGCB\nJk+erGQyqQcffFC7du3SkiVLJEmLFy9Wd3d3pA0FUB5MewLsUFTK+j//+Y8GBwd1++23q7e3V8uX\nL9fAwICXom5vb1dPT0+kDQUAoJYVfQ/52LFjevzxx/Xpp5/q5ptvHjEohAEiAAAUpqiUdXt7uy66\n6CIlEgmdddZZmjRpkiZNmqTBwUFJ0sGDB5VMJiNtKAAAtayogHzxxRfr7bffViaT0dGjR9Xf36+F\nCxdqx44dkqSdO3dq0aJFkTYUAIBaVnSlrj/84Q/q6uqSJP3kJz/RnDlztGrVKg0NDWnmzJlau3at\nGhsbI20sAAC1itKZAABYgEpdAABYgIAMAIAFCMgAAFiAgAwAgAUIyAAAWICADACABQjIAABYgIAM\nAIAFCMgAAFiAgAwAgAUIyAAAWICADACABQjIAKznuq5YBwe1joAMAIAFEtVuAADkEovFqt0EoOzo\nIQMAYAECMgAAFiAgAwBgAQIyAAAWICADOWQymWo3AciJaWHjHwEZAAALMO0JGIPpGfuLUjD9pnL8\nPT72e27+8zQep681HnHUAACwAD1kYAymVxaPx7k/VwX0igtnsjr0kMcnjhoAABYgIAMAYAFS1kBA\n2ACuUtOnruuSgkXZVSpVzYC78qCHDACABeghAwHluOKnF4Fyc123Yj1kzufyoIcMAIAFCMiWYFqN\nfTKZjDKZjBzHGVF0oRhRbKNcbG0XChOPx71zFuMTARkAAAsQkAEAsACDuipsrJrIsViMesmWCKZv\n4/F4JMfE1uNbjvYU+1n9KdeGhoaitlGvYrFYxac9VXIgWT1gTwIAYAF6yEBAsIccRQ+tXuphl/oZ\n/fs62FNGdpUsPmPeh+xFtOghAwBgAXrIFcYVpf3KdU+MY59bLBZTInHyZ8lxHEmUHc0X5SzHv5J+\neQYHB7V06VL96U9/0oEDB3TTTTepo6NDK1as0PDwcFRtBACg5pUUkH/3u9/ptNNOkyQ99thj6ujo\n0EsvvaRZs2apq6srkgYCAFAPig7IH330kT788ENddtllkqRdu3ZpyZIlkqTFixeru7s7kgbWC6rr\n2MdxHDmOo1QqVfK2bBzQZSp0RVmpKxaLjfhfKeLxOFNqClDJNLU5Z8xtBUSj6LN93bp1Wr16tfff\nAwMDampqkiS1t7erp6en9NYBAFAnihrU9corr+irX/2qvvjFL4b+3cbegC3GmlLDgAx7mGPR29sr\n6WRPedq0aZKKn4Ljz4CYQUu2iLJgSanb8g/g4ntQmEruL/NeZDCiVdQvwxtvvKFPPvlEb7zxhv77\n3/+qqalJLS0tGhwcVHNzsw4ePKhkMhl1WwEAqFkxt8Tu7MaNG3XmmWfqvffe0/z583XNNdfoV7/6\nlc477zwtW7YsqnbWjGw9ZAoh2MHcF0un05JO9mhL7RFkMhlv5kFjY6Ok2jzO5ehtR7W9WsV+qh2R\n5RuWL1+uV155RR0dHTp27JiuvfbaqDYNAEDNK7mHjMLQQ7YfPeTi0UOuPPZT7bBrdEkdCfvi+FdQ\nGes5qBwTOP0rcZXCzEKwZSBMOc4zztnKM/vccRzv3Cr3cfD/VjEILzp2/DIAAFDn6CFbotbXFR1P\nvf6wVHKp7XYcx7oUdTAjE8X5F+U2x8O5YpNqrKnOMYpW7UYAAADGEXrIFWYGDJkrS9NrSqfTXm/C\ntsIRUch2f9z2q+yoVhsyx96WTIg5FqZd5h53KczAxGJ7yP5yjOa7Yfv5YYtKrrnNMSkPO34ZAACo\ncwRkAAAsUHu50TIaaw5xIa/Plsrzz3utNcF9NR5SXmaVJ8dxSp6ylEgkvHSu+bfaqevg+0cxIKjU\nz+RfJYp5+YWr1HQnf/2EKAcF1jv2IAAAFqBSVwVlu5r0V3KyrYBElMZDVSEzqMh/rIotfmB6eY7j\neJkP2z53qZkfv+C63qWcw+PhXLFJJpMp+2+GOSb+LA/HJjq194sPAMA4VHs3K8uo1Ht//h5yUCwW\n80o11mLSIthzCitHacuVdrBudRTtymQy1hVHibI3a5RaGCSsFGMtfh/KpdznWPDY2HIu1wp6yAAA\nWICADACABUhZ5ymKtFk8HvcGbpntmYE+juOUvMTfeGMGTxkNDQ1WpMCi3P9mW01NTaNSxNU2NDQk\n6VTquqWlRVJpacjga/Otcmam/A0NDXnPnzBhgqSRFahsOD9sVe5KXf5t18tvVKWxVwEAsAA95BzM\nVeHw8LB3Fd/c3Cyp8IIFruuOWewgnU577zVx4sSS2myjsEEgtl9l+6c/lVpX2T+IzZbCIOaz9PX1\nSTrVI81WmKZcU2vM/m1pafG+Z+bfxsbGqu+r8SCqmutjicVio2rx+wu5oHSc5QAAWKAue8iF3I8y\nz0kkEt7VoSmpWGgP2b8mbvC1DQ0NOnHihCR5059sK6FZritw23o/g4ODkqQPPvhAkjR16lSdddZZ\nkk4dm3z5pwHZtnqR6RFPmzZNUmHfh3z/nu9n9T/P7GPb7rnbyuyn4eHhihUV8mcvEB27fgkBAKhT\nBGQAACxgV060AgqdFuBPb5v0TLZ0ULZ0eLYUdyKR8P5upqPYMg3IiKIt/hSuTZ9NOpX6+/TTTyVJ\nU6ZMkSSdeeaZJadPh4eHvfPHltWL/LdjCn1NLsVOv/GfF+Z7RqWu7Pz7yUyrNANPy/Vetn13awU9\nZAAALMBqT3nKNmWpEMFpA/6rWzNQwjxnwoQJNXclGna6+WsWV/PzmuNrBnX5B8iYvxU70G5oaMjb\nhum9VPvYjnUuliJYyzrfaTH+VbGCRXNsG/Rnq0wm4/2GmHM3Sul0OvQ30JaMTy3gTAcAwAL0kPPk\nOI53dVjsUP9UKuXd4zHFP8zVfyqVKuqe3nhh68pO+Sq1mEcmkxk1Xa7ax7m/v1+SNDAwIOnk9C4p\ne48nVxYjiuNs9rW/N2bL+VLtLE4u5SwxmslkvHPGnLu1mMWrJnrIAABYgIAMAIAFai83Wib+QV3F\npoX8lbqCqc9YLOalNM3famkwy3hOa2UymaLb7x/kZCpj2cK0xwzuMv+WMkgnOKirmG0Fp9bYlCa2\npR1+/hrp5fzNiMfj3jljBo/ZdGxqQe384gMAMI4xqCsHs3uGhoa8q/1iB3X5d3XYurGmIIj5W1NT\nU11cfdq21q05Dp9//rmkkz2D1tZWSYUPxDJZj4GBAW+94WoP5goKFj3JVfgmn0FdhU4RzPXdGOtv\nGLkiXTkHDLquGzptsZYyedXGngQAwAJ2XapbJHgl2NjY6PV2SpmeNNa0kFgs5l3dmsIU/nKaNoji\nfpG/NxzcF9XuCZlenVkf2GRCJk6cWHTpTHP8JkyYMOoerS29vXL0cPwFb/L5nGY6YDqd9vZPpVYu\nGu/8GbVyrpA1PDzs/QaaaZv+77Et5/N4xpkOAIAFCMgAAFiAQV1jCA5OicViXlrNpGYKncYyPDzs\nbc+81j+1I/jeNqbqik1P+fej+dfWVFewXaXUMfdPAwre8ihHveFCmBR6sHZ0NvkO6ir0mPpfF5xe\nGI/HrTtHohTl96Cc3ynHcUZNzWxsbKzpY1Np9v3iAwBQh4ruIa9fv17vvvuu0um0brvtNs2ZM0cr\nV66U4ziaPn26NmzYUPUegJ/5mOl0Oq/VZMIGRwR7roVeGZrJ9P739m/b5p6xFP2gK1t7yGFKbWu2\nVa6K2UYU+8ycj6aWtcna2PS9lewqPhF1W6o9kLFQYat5Bf9W6d8vm86PUhU1yvrtt9/WP//5T23d\nulVHjx7V97//fS1YsEAdHR268sor9eijj6qrq0sdHR1RtxcAgJpUVA/ZcRwNDQ2ppaVFjuNo4cKF\nmjRpkrZv366mpia99957evbZZ7Vx48ZytLkoZirR0NCQJk+eLCn7/cBgD9nfgw2712Z6G+Z1/l6G\neV0qlcraKw9uIx6PW1VEIsppT1L4/fPg32wQ1mZ/Oc187qmm02nvWBb72cz9O/Pdk0aeR8HeS749\nFVMAxRREmTZtWll6OeOtN1iqsJKWYZ87qkxRvudkFLJ9jyt9bGuph1zUt66hocH7Qejq6tIll1yi\ngYEBLwi1t7erp6cnulYCAFDjSroMfu2119TV1aX77rtvxOMM3AYAoDBF50PffPNNPfnkk3rmmWfU\n2tqqlpYWDQ4Oqrm5WQcPHlQymYyynSUzKaOJEyfmNXUlLAWSLS1itplt5ZVc0zfM880i4LFYTJMm\nTRqx3WIHlNkiLE0dNjCkGsw0IJMaNrcQ/KvcmONsjpEk7xZINv5a5aYCWKFTqMyxdxzHa6v/HPOn\n0817+h8fS3NzsySVnFLPJdt2wwZR2jq40c+02xyPsDr3sVgs62ePahpZPB4v6/cnlUp52zef09+u\nav0mjdffwjBFnfEnTpzQ+vXr9dRTT2nq1KmSpIULF2rHjh2SpJ07d2rRokXRtRIAgBpXVA/51Vdf\n1dGjR/Wzn/3Me+yhhx7Svffeq61bt2rmzJm69tprI2tkFMKu6AqR71VutkFYrut6V9JhzzM9gilT\npkgqbR3esPf2DxbztzlfUV6JjrWtal7tmh6xGf/Q1tYmKbwATFgt7jDm8/hroRdbZMQcN5M1GUuh\nKy75606b11W6hnpYb9jGaXHDw8Oh08LM9zoWi43KNOTTAx7redX8jgbF43HvcxZ7DiO7uqnUVeiX\nu9iRv9lGH6bT6YIWpvAH5GD7i5nDWmpArnUmpXzo0CFJpwKySelKp36A+vr6vGOSb8o6WKmr0GU8\nzfuZH0Up+4h/8z65fjTNeWE+f1NTkxU/tOMhIJt9Z6r4JRKJgmZGjKeR5/5bJeb8sOE8qSU1GZDL\ndaWf7YcurDRkkP8+WbBHUO4vZl9fn06cOCHp5Ch4qfh1nWtVtp5lWDnNShdC8E9rCjvPwkpOBp/j\nF7xnbjQ2Npb8vbExmEbhrbfe0te//nUv6Povjoxiy6tmmxJl2LI/a/X4Vpv9oyYAAKgDBGQAACxQ\nkylrw3GcyO6X+u/Bmm35U5WmEphJa0+aNGnUe2arKOO67oha10YwHVpsKjGVSnnb4h5y5eU6F/NJ\nAfrPv7DnmXvAZlvBFcXGek9z/9P8d1NT07iYclQNJ06c0MSJE72UdbZVzEwFNOnUQLxCB68Vkhqu\npYpVhailz823DgAAC9R0D3ksZiBGcDJ/rukJ2QbxBFfOaW5uHjVoKlet2eBoV/9jZrunnXbaiDbn\nq5auIm2QbeUuP/8Ie8NkOQrtheZ6z+CUFLP9XFmVsBV8qlGP2P+vZGdhkOD3KLjP/cfFZM1isVjO\nbMV44P8NrFTN7HzU0m+bfWc8AAB1qG56yOY+2VtvvaXFixdLkpYvXy5JeuSRRySN7HWGTXMx8i0B\nGLzCz2Qy3nbyuRfs31ZwyhVTlqIXnOcbNt/XHLd8e8h+wWlJ2aZVhTHtSafT3lzYsN6aUehYAf/r\nix2rEOU0nfEwtca/kpt0sq3FZkBsl2scTbXQQwYAAJEiIAMAYIGaTFmHpZc//vhjSdKGDRu8dN93\nv/tdSfIWwvCngYOpmeD/L0bYClD+Npcz7ZLJZEZVoCrm/Qo5XcZbGsnsH5N+9JcHDBvQV62UquM4\n3nv70+XFlocNS6VnmypVbAnZYtlUXjKVSoXe2gr7bxvSuRhfOGMAALBATfaQzXQD/zSjI0eOSJJO\nP/10bwpCcHqIf9BCcFBLritfMyAmrOfi38ZYV/iZTGbUGrdh00+K7SE4jjNqakYlexu2DdAx+8J/\nDpSzR5MtO1KMsMFThQ6oypYRCCtqk+92g6+z5ZhHYXh4WI2NjWMu+uKXbYBnOaTT6VHFfzC+cNQA\nALBAUesh2870hrds2aKpU6dKki677DJJ0plnnjnmsnRDQ0Pe0nvJZFLSqfKDruuqr69Pkrx70P5l\n+cw2zXSYsXpcY60KFY/HRxWRCJvSYtoz1hXwWD31hoaGSFbwKWU9aX+7/I9VQ7An4e/N5MM/hS2f\nKSCZTMY7ruaYFNqLybdwR749ZfP+5nwOK91a6jSmYu5nB/erTUv8ha2FLGlEdsu0u9I95Fgs5mU7\nzH3uqLMyweUXayn74VetzA49ZAAALEBABgDAAjWZsm5vb5ckfelLX9Lpp58uSZo9e7ak7CmWRCKh\n/v5+SdLRo0clnUpdO47jpYHCBmyZ1JA/xR3kT8eFbcM/qCbstbna729HoWP1zPZNSiqRSIQOKAtb\nkN3/d/+/ruuOSpnZmuLKtgqPP33l/2zBfRwcJOiXSCQKPiZB/rrJYanTYtPL2aq/BW815BqcFlYX\nO/iYP60bfB//ue8/J21doSzYHsdxvM+QbwW3qPj3nbn9EMWtqjD+c922YxKFan0mesgAAFigJqc9\nGcXcmDdTpswALjMozL+tUur8llpwoVj5rtSSa9DVWMUk/IPS8ikwMVYbg8q1T8Kmq5ge6LFjxyRJ\nn332maSTn+2MM86QdGpd22oUyDArfv3rX//y2tPW1uZt27Q/eHyzTbXL53n+5/qzHvkMLAvLLhQj\nyhrZpRhv07jK1V7/8a32FKvxdkyyoYcMAIAFarqHXIxgDzDfe1dh66KGFVcYaztDQ0OjipIUev8n\nrDdmHhsYGPBWvJo8ebLXxnLI1g6/avZyzJrT5rg1NTV5bTTZkYkTJ0oaef/X7LN8SyT6V47KZ93t\nXO2WTmZxTpw4IUmaMmWKpJFT8PLtTZopMmbcREtLi6TqrCRmW+GYsZw4cUKTJ08eNbUpLAvgP/bF\nTnXLh2lDOp0eNQ4lyt5jrvXcq6UcPeRqnY/0kAEAsAABGQAAC9RNytqkdfr6+rxKXtOmTZN0Ku3n\nT08EKzflSjUFB4O1traOmpriOI6XJjR/81eKCm5jwoQJ3t9N+itbWtF1XW/gj+FPZWb7LGFTU4JS\nqZS3j8aq1e3n35/BWwF+la7E5K9Z7p/GVUhaMZVKjZoCZl7v3zfmffr7+719YI69+dc/ICvfWyRm\nW8HKSf6/5TuoK1ihK2xKVb5Vp/yV6sy/2W5XmL+ZWwjpdHrEoEDTHlsqQ5m0cLAyn78Km/ns/pr6\n5vZHOacgDQwMeO0wvxNht86KlUqlvNteZnpnpad2jSXqFLN/+lol0UMGAMACNdlDDl6lS9JHH30k\nSXrxxRd19tlnS5IWL14sSfrCF74gaeTVVViBjeBUn7C1aP2CvYB0Op21hxkm2LPMVTc52APNdxBG\nsMfY0NAw6j0cxwmtd+xvpzS695/ve/rbWc5Va6KYiuQ4zqhpRuaKOt9jky1TUcpa1WHTz/LhP8fC\nCl5II9cDDtuueZ6/HntwAFRDQ8Oo899/TIK9f8dxRu1jW3rMhr+GfDVXXAquYpZr6mEh55vrut5x\n9W+/2sci6pXUqqk2PgUAAONcTfaQzZSQAwcOjFrRJplMevdVgx89lUp593jNPR/z+lQqpX//+98j\nXjd79uyCpyXZckVfDlGs0WtLAQgp+uIWpfJnEsLOu2L3dSErRxWyffP6Wj7nS5Vr/5R6b7QSBYeq\nfXxTqdSIrES121MKesgAAFiAgAwAgAVqMmVtBhz4Uxn5VB/yL8AdHESSTqdHDRZrbGwMXYzc/5yw\n9xirrWagiz8dWWgt6LGePzw87E0tMel7M3Uhiu3n89qgag4CCRskZ25XmGlxx48f914zc+ZMSSen\nswVl+xz+wT7ZBvLlk5o002iOHDmi0047TdKp6S1h04ty7V9zPgSnY1VjgMx4qdSVTqdDB3Nmq/ue\n65ZHFGnpfN6nVDakpyupGp+XHjIAABaoyR5yNZjelelF+4sZGI7jeIU7zJWX6ZWk0+nQXpu/Jq2U\nfc3ksB6+v4CBaZvJFoxVXMSa6RG2AAAGjUlEQVT/uuBnzLbiVbaCFP5pM0a2KSzlHojin1Ijjexh\n+uuRm7YEH3McZ1S987DpLmafDw4Ojioc4u9phRXUCGu3aV9wXzc0NIzqIWcr8iKdOhbBYjVhPflc\nqz0Fi4yEDbIJq/9tXuevLR7cB/4peGHnViV7MSaTFcyMha0PbPZrrrXUS+X/bpn3Nu+Xz9rVUn77\nMJPJjFhn2f9vtUW5qpp0qm43PWQAAOoQPeSIZbtSy3dN4mzbLfcVW657YvncM8v3swULWISxecJ/\nPvds8502FOV0r3JMHfP3zrOV9wwrZBPsIYf1PML2U9j5Ue0e8lii7qEFt1uue8JGob9D2Y5lpdm6\nClUx7P21AwCgjhCQAQCwQOQp61//+tfas2ePYrGY1qxZowsvvDDKzQMAKsifprb5FlItiHTI39//\n/nd9/PHH2rp1qz766COtWbNGW7dujfItAACoSZEG5O7ubi1dulSSdM455+j48eP6/PPPNXny5Cjf\npuqqWcSgXINHkF1wSpqU3/rPtg0+MqIsepDvWsn1oNDvZzHHYazpbeU+12wdPDVWkrccRVjKLdJv\nz+HDhzVt2jTvv9va2tTT0xPlWwAAUJOin6XuU6szqqp5dWXrlV2tC+v5ZTsWth+nKNtX771iv0L3\nazHHIfiacp9rha7hXmmFfH7bv5eRfpOSyaQOHz7s/fehQ4c0ffr0KN8CAICaFGlA/uY3v6kdO3ZI\nkj744AMlk8mau38MAEA5RJqDmDdvnr7yla/oxhtvVCwW0/333x/l5gEAqFmUzgQAwAKMxgAAwAIE\nZAAALFC1ceyU2IzGrl27tGLFCp177rmSpC9/+cu69dZbtXLlSjmOo+nTp2vDhg3eWrfIbt++ffrp\nT3+qW265RZ2dnTpw4EDovty2bZuef/55xeNx3XDDDVq2bFm1m2614H5dvXq1PvjgA02dOlWS9KMf\n/UiXXXYZ+7VA69ev17vvvqt0Oq3bbrtNc+bM4XwtUXCfvv7665U7V90q2LVrl/vjH//YdV3X/fDD\nD90bbrihGs2oCW+//ba7fPnyEY+tXr3affXVV13Xdd1HHnnEffHFF6vRtHGnr6/P7ezsdO+99173\nhRdecF03fF/29fW5V1xxhdvb2+sODAy4V111lXv06NFqNt1qYft11apV7uuvvz7qeezX/HV3d7u3\n3nqr67qu+9lnn7mXXnop52uJwvZpJc/VqqSsxyqxiWjs2rVLS5YskSQtXrxY3d3dVW7R+NDU1KRN\nmzYpmUx6j4Xtyz179mjOnDlqbW1Vc3Oz5s2bp927d1er2dYL269h2K+F+drXvqbf/va3kqQpU6Zo\nYGCA87VEYfvUcZxRzyvXPq1KQKbEZrQ+/PBD3X777frBD36gv/3tbxoYGPBS1O3t7ezbPCUSCTU3\nN494LGxfHj58WG1tbd5zOH+zC9uvkrRlyxbdfPPN+vnPf67PPvuM/VqghoYGtbS0SJK6urp0ySWX\ncL6WKGyfNjQ0VOxctaIWmsvMq6KdffbZuvPOO3XllVfqk08+0c033zziio59G52x9iX7uHDXXHON\npk6dqgsuuEBPP/20Hn/8cV100UUjnsN+zc9rr72mrq4uPfvss7riiiu8xzlfi+ffp3v37q3YuVqV\nHjIlNqMzY8YMfec731EsFtNZZ52l008/XcePH9fg4KAk6eDBgzlThRhbS0vLqH0Zdv6yjwuzYMEC\nXXDBBZKkb33rW9q3bx/7tQhvvvmmnnzySW3atEmtra2crxEI7tNKnqtVCciU2IzOtm3btHnzZklS\nT0+Pjhw5ouuuu87bvzt37tSiRYuq2cRxbeHChaP25dy5c/X++++rt7dXfX192r17t+bPn1/llo4v\ny5cv1yeffCLp5H36c889l/1aoBMnTmj9+vV66qmnvBHAnK+lCdunlTxXq1ap6+GHH9Y777zjldg8\n//zzq9GMce/zzz/XL37xC/X29iqVSunOO+/UBRdcoFWrVmloaEgzZ87U2rVr1djYWO2mWm/v3r1a\nt26d9u/fr0QioRkzZujhhx/W6tWrR+3L7du3a/PmzYrFYurs7NTVV19d7eZbK2y/dnZ26umnn9bE\niRPV0tKitWvXqr29nf1agK1bt2rjxo2aPXu299hDDz2ke++9l/O1SGH79LrrrtOWLVsqcq5SOhMA\nAAtQqQsAAAsQkAEAsAABGQAACxCQAQCwAAEZAAALEJABALAAARkAAAsQkAEAsMD/ABesan6M3XKY\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2de7039fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sDhR5asOLXsz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transcript = open(\"61-70968.trans.txt\",'r')\n",
        "input_text = [s[14:] for s in transcript.read().strip().split('\\n')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2faiZ8BNax5h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creates the text input array associated with each png, and trims the number id"
      ]
    },
    {
      "metadata": {
        "id": "vMiwnfALQxKB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "f9028c0c-c774-411f-c570-96d6f9c85a62"
      },
      "cell_type": "code",
      "source": [
        "getSpec(\"61-70968-0045.flac\",\"\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.42157549e-02, 5.10279942e-02, 3.05857292e-02, ...,\n",
              "        2.97752282e-02, 3.32919954e-02, 6.64239971e-02],\n",
              "       [2.25256377e-01, 3.11466151e-01, 3.48730247e-01, ...,\n",
              "        3.40292110e-01, 3.63837222e-01, 3.33525963e-01],\n",
              "       [4.09767939e-01, 4.06295238e-01, 4.28071143e-01, ...,\n",
              "        3.94537000e-01, 4.27594334e-01, 3.41218474e-01],\n",
              "       ...,\n",
              "       [3.35674966e-06, 5.65848098e-06, 6.06927857e-06, ...,\n",
              "        5.25640117e-06, 5.57153649e-06, 3.55566657e-06],\n",
              "       [3.87379064e-06, 5.93787920e-06, 4.47170654e-06, ...,\n",
              "        3.32399630e-06, 4.41597586e-06, 2.84882848e-06],\n",
              "       [1.82231047e-06, 2.39589387e-06, 3.19921286e-06, ...,\n",
              "        5.76976906e-06, 7.30103853e-06, 5.42571646e-06]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2de707a6d8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KbHSALobcz7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def melspectrogram(wav, samplerate):\n",
        "\treturn librosa.feature.melspectrogram(wav, samplerate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qF18Nd7ZqKDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d20c077d-ee16-490e-db16-d83fb174ca8d"
      },
      "cell_type": "code",
      "source": [
        "len(s[0])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "0AtVbbxG3nB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "c1e496da-2e98-4e38-ac90-08133ef64fa7"
      },
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(' '.join(x for x in input_text).split(' '))#integer encode all words\n",
        "input_ints = [label_encoder.transform(x) for group in input_text for x in group ]"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-dbfb66b9bbcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#integer encode all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-195-dbfb66b9bbcc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#integer encode all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[1;32m    127\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classes_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape ()"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p4CyKGBL_YCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stopped here because spectrograms are for sentances, and the inputs are sentances, however, if the text is broken up by word, they either loose their order (being fed in as one-hot encoded words), or as sentances in which case only inputed sentances are inputted. The actual paper uses characters as input, but i don't know how the spectrograms from sentances can be applied to that."
      ]
    },
    {
      "metadata": {
        "id": "6bGsSdzq_X8X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is possible code for the actual network components, though I am uncertain about their relations/usage. Taken from https://github.com/Rayhane-mamah/Tacotron-2/blob/master/tacotron/models/modules.py\n"
      ]
    },
    {
      "metadata": {
        "id": "i0kFgSAw6-gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN:\n",
        "\tdef __init__(self, is_training, size=256, zoneout=0.1, scope=None):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tis_training: Boolean, determines if the model is training or in inference to control zoneout\n",
        "\t\t\tsize: integer, the number of LSTM units for each direction\n",
        "\t\t\tzoneout: the zoneout factor\n",
        "\t\t\tscope: EncoderRNN scope.\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(EncoderRNN, self).__init__()\n",
        "\t\tself.is_training = is_training\n",
        "\n",
        "\t\tself.size = size\n",
        "\t\tself.zoneout = zoneout\n",
        "\t\tself.scope = 'encoder_LSTM' if scope is None else scope\n",
        "\n",
        "\t\t#Create forward LSTM Cell\n",
        "\t\tself._fw_cell = ZoneoutLSTMCell(size, is_training,\n",
        "\t\t\tzoneout_factor_cell=zoneout,\n",
        "\t\t\tzoneout_factor_output=zoneout,\n",
        "\t\t\tname='encoder_fw_LSTM')\n",
        "\n",
        "\t\t#Create backward LSTM Cell\n",
        "\t\tself._bw_cell = ZoneoutLSTMCell(size, is_training,\n",
        "\t\t\tzoneout_factor_cell=zoneout,\n",
        "\t\t\tzoneout_factor_output=zoneout,\n",
        "\t\t\tname='encoder_bw_LSTM')\n",
        "\n",
        "\tdef __call__(self, inputs, input_lengths):\n",
        "\t\twith tf.variable_scope(self.scope):\n",
        "\t\t\toutputs, (fw_state, bw_state) = tf.nn.bidirectional_dynamic_rnn(\n",
        "\t\t\t\tself._fw_cell,\n",
        "\t\t\t\tself._bw_cell,\n",
        "\t\t\t\tinputs,\n",
        "\t\t\t\tsequence_length=input_lengths,\n",
        "\t\t\t\tdtype=tf.float32,\n",
        "\t\t\t\tswap_memory=True)\n",
        "\n",
        "\t\t\treturn tf.concat(outputs, axis=2) # Concat and return forward + backward outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COgWXXGJCGW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderConvolutions:\n",
        "\t\"\"\"Encoder convolutional layers used to find local dependencies in inputs characters.\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, is_training, hparams, activation=tf.nn.relu, scope=None):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs:\n",
        "\t\t\tis_training: Boolean, determines if the model is training or in inference to control dropout\n",
        "\t\t\tkernel_size: tuple or integer, The size of convolution kernels\n",
        "\t\t\tchannels: integer, number of convolutional kernels\n",
        "\t\t\tactivation: callable, postnet activation function for each convolutional layer\n",
        "\t\t\tscope: Postnet scope.\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(EncoderConvolutions, self).__init__()\n",
        "\t\tself.is_training = is_training\n",
        "\n",
        "\t\tself.kernel_size = hparams.enc_conv_kernel_size\n",
        "\t\tself.channels = hparams.enc_conv_channels\n",
        "\t\tself.activation = activation\n",
        "\t\tself.scope = 'enc_conv_layers' if scope is None else scope\n",
        "\t\tself.drop_rate = hparams.tacotron_dropout_rate\n",
        "\t\tself.enc_conv_num_layers = hparams.enc_conv_num_layers\n",
        "\n",
        "\tdef __call__(self, inputs):\n",
        "\t\twith tf.variable_scope(self.scope):\n",
        "\t\t\tx = inputs\n",
        "\t\t\tfor i in range(self.enc_conv_num_layers):\n",
        "\t\t\t\tx = conv1d(x, self.kernel_size, self.channels, self.activation,\n",
        "\t\t\t\t\tself.is_training, self.drop_rate, 'conv_layer_{}_'.format(i + 1)+self.scope)\n",
        "\t\treturn x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0SHgiSU4Chvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TODO: a lot, still need to implement tf session \n",
        "notes from paper: input characters use 512-dimensional embedding, stack of 3 conv. layers with 512 filters and shape 5x1 (each filter spans 5 characters followed by batch normalization and ReLU activation). the output of conv. is passed to a single bi-directional LSTM with 512 units(256 in each direction) "
      ]
    },
    {
      "metadata": {
        "id": "AWw1QpKKJckT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''From the tutorial at https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/\n",
        "'''\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras import regularizers, constraints, initializers, activations\n",
        "from keras.layers.recurrent import Recurrent\n",
        "from keras.engine import InputSpec\n",
        "\n",
        "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
        "\n",
        "class AttentionDecoder(Recurrent):\n",
        "\n",
        "    def __init__(self, units, output_dim,\n",
        "                 activation='tanh',\n",
        "                 return_probabilities=False,\n",
        "                 name='AttentionDecoder',\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
        "        encoder and outputs the decoded states\n",
        "        :param units: dimension of the hidden state and the attention matrices\n",
        "        :param output_dim: the number of labels in the output space\n",
        "\n",
        "        references:\n",
        "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
        "            \"Neural machine translation by jointly learning to align and translate.\"\n",
        "            arXiv preprint arXiv:1409.0473 (2014).\n",
        "        \"\"\"\n",
        "        self.units = units\n",
        "        self.output_dim = output_dim\n",
        "        self.return_probabilities = return_probabilities\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "        self.name = name\n",
        "        self.return_sequences = True  # must return sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
        "          for model details that correspond to the matrices here.\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
        "\n",
        "        if self.stateful:\n",
        "            super(AttentionDecoder, self).reset_states()\n",
        "\n",
        "        self.states = [None, None]  # y, s\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for creating the context vector\n",
        "        \"\"\"\n",
        "\n",
        "        self.V_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='V_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='W_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='U_a',\n",
        "                                   initializer=self.kernel_initializer,\n",
        "                                   regularizer=self.kernel_regularizer,\n",
        "                                   constraint=self.kernel_constraint)\n",
        "        self.b_a = self.add_weight(shape=(self.units,),\n",
        "                                   name='b_a',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the r (reset) gate\n",
        "        \"\"\"\n",
        "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_r',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_r = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_r',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        \"\"\"\n",
        "            Matrices for the z (update) gate\n",
        "        \"\"\"\n",
        "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_z',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_z = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_z',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for the proposal\n",
        "        \"\"\"\n",
        "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='C_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
        "                                   name='U_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
        "                                   name='W_p',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_p = self.add_weight(shape=(self.units, ),\n",
        "                                   name='b_p',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "        \"\"\"\n",
        "            Matrices for making the final prediction vector\n",
        "        \"\"\"\n",
        "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
        "                                   name='C_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
        "                                   name='U_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
        "                                   name='W_o',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
        "                                   name='b_o',\n",
        "                                   initializer=self.bias_initializer,\n",
        "                                   regularizer=self.bias_regularizer,\n",
        "                                   constraint=self.bias_constraint)\n",
        "\n",
        "        # For creating the initial state:\n",
        "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                                   name='W_s',\n",
        "                                   initializer=self.recurrent_initializer,\n",
        "                                   regularizer=self.recurrent_regularizer,\n",
        "                                   constraint=self.recurrent_constraint)\n",
        "\n",
        "        self.input_spec = [\n",
        "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x):\n",
        "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
        "        self.x_seq = x\n",
        "\n",
        "        # apply the a dense layer over the time dimension of the sequence\n",
        "        # do it here because it doesn't depend on any previous steps\n",
        "        # thefore we can save computation time:\n",
        "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
        "                                             input_dim=self.input_dim,\n",
        "                                             timesteps=self.timesteps,\n",
        "                                             output_dim=self.units)\n",
        "\n",
        "        return super(AttentionDecoder, self).call(x)\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # apply the matrix on the first time step to get the initial s0.\n",
        "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
        "\n",
        "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
        "        # output_dim)\n",
        "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
        "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
        "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
        "        y0 = K.tile(y0, [1, self.output_dim])\n",
        "\n",
        "        return [y0, s0]\n",
        "\n",
        "    def step(self, x, states):\n",
        "\n",
        "        ytm, stm = states\n",
        "\n",
        "        # repeat the hidden state to the length of the sequence\n",
        "        _stm = K.repeat(stm, self.timesteps)\n",
        "\n",
        "        # now multiplty the weight matrix with the repeated hidden state\n",
        "        _Wxstm = K.dot(_stm, self.W_a)\n",
        "\n",
        "        # calculate the attention probabilities\n",
        "        # this relates how much other timesteps contributed to this one.\n",
        "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
        "                   K.expand_dims(self.V_a))\n",
        "        at = K.exp(et)\n",
        "        at_sum = K.sum(at, axis=1)\n",
        "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
        "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
        "\n",
        "        # calculate the context vector\n",
        "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
        "        # ~~~> calculate new hidden state\n",
        "        # first calculate the \"r\" gate:\n",
        "\n",
        "        rt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_r)\n",
        "            + K.dot(stm, self.U_r)\n",
        "            + K.dot(context, self.C_r)\n",
        "            + self.b_r)\n",
        "\n",
        "        # now calculate the \"z\" gate\n",
        "        zt = activations.sigmoid(\n",
        "            K.dot(ytm, self.W_z)\n",
        "            + K.dot(stm, self.U_z)\n",
        "            + K.dot(context, self.C_z)\n",
        "            + self.b_z)\n",
        "\n",
        "        # calculate the proposal hidden state:\n",
        "        s_tp = activations.tanh(\n",
        "            K.dot(ytm, self.W_p)\n",
        "            + K.dot((rt * stm), self.U_p)\n",
        "            + K.dot(context, self.C_p)\n",
        "            + self.b_p)\n",
        "\n",
        "        # new hidden state:\n",
        "        st = (1-zt)*stm + zt * s_tp\n",
        "\n",
        "        yt = activations.softmax(\n",
        "            K.dot(ytm, self.W_o)\n",
        "            + K.dot(stm, self.U_o)\n",
        "            + K.dot(context, self.C_o)\n",
        "            + self.b_o)\n",
        "\n",
        "        if self.return_probabilities:\n",
        "            return at, [yt, st]\n",
        "        else:\n",
        "            return yt, [yt, st]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "            For Keras internal compatability checking\n",
        "        \"\"\"\n",
        "        if self.return_probabilities:\n",
        "            return (None, self.timesteps, self.timesteps)\n",
        "        else:\n",
        "            return (None, self.timesteps, self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "            For rebuilding models on load time.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            'output_dim': self.output_dim,\n",
        "            'units': self.units,\n",
        "            'return_probabilities': self.return_probabilities\n",
        "        }\n",
        "        base_config = super(AttentionDecoder, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foc6wVZPAwtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The below is a network thing that has been removed in recent versions of keras, so I found and copied the code. The newer version doesn't translate over as cleanly, so this seemed like the easier approach. from https://github.com/datalogue/keras-attention/issues/15"
      ]
    },
    {
      "metadata": {
        "id": "YJxgJNT7KN9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
        "                        input_dim=None, output_dim=None,\n",
        "                        timesteps=None, training=None):\n",
        "  \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
        "  # Arguments\n",
        "      x: input tensor.\n",
        "      w: weight matrix.\n",
        "      b: optional bias vector.\n",
        "      dropout: wether to apply dropout (same dropout mask\n",
        "          for every temporal slice of the input).\n",
        "      input_dim: integer; optional dimensionality of the input.\n",
        "      output_dim: integer; optional dimensionality of the output.\n",
        "      timesteps: integer; optional number of timesteps.\n",
        "      training: training phase tensor or boolean.\n",
        "  # Returns\n",
        "      Output tensor.\n",
        "  \"\"\"\n",
        "  if not input_dim:\n",
        "      input_dim = K.shape(x)[2]\n",
        "  if not timesteps:\n",
        "      timesteps = K.shape(x)[1]\n",
        "  if not output_dim:\n",
        "      output_dim = K.shape(w)[1]\n",
        "\n",
        "  if dropout is not None and 0. < dropout < 1.:\n",
        "      # apply the same dropout pattern at every timestep\n",
        "      ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
        "      dropout_matrix = K.dropout(ones, dropout)\n",
        "      expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
        "      x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
        "\n",
        "  # collapse time dimension and batch dimension together\n",
        "  x = K.reshape(x, (-1, input_dim))\n",
        "  x = K.dot(x, w)\n",
        "  if b is not None:\n",
        "      x = K.bias_add(x, b)\n",
        "  # reshape to 3D tensor\n",
        "  if K.backend() == 'tensorflow':\n",
        "      x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
        "      x.set_shape([None, None, output_dim])\n",
        "  else:\n",
        "      x = K.reshape(x, (-1, timesteps, output_dim))\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}